## 2018-03-16
* MC: emailed groups my understanding of an outline of their work; annotated research chapter; updated `prep_basedisp.R` to add proportions by race in DSS referral data, updated `analysis_basedisp.R` to improve figures, generate disproportionality in referral point estimates and intervals by year; added more structure to report document, and started adding a little bit of content.

### Group 1

* HS: This week I read and summarized my assigned article. I also did initial logit regressions comparing the chances of an investigation for white and non-white children. I ran into some issues making combined dummy variables, that will hopefully be worked out in class. My main issue is that multiracial children are classified often as black and white, so they could be counted twice. I need to figure out a way to address this. I also pulled poverty statistics by census tract for some initial judgements on poverty and investigation. 
* NP: I read the assigned four articles carefully and made annotation that I thought could be useful to the project. I also tried to build models based on our discussion last class. Besides, through my readings, it seems considering changes in policies would make our analysis become too complex, since the changes could have different influence on different races.
* MW: I read the required articles and am just about to read the additional one! Our group is working to split the tasks you suggested for us in the previous email. I am particularly going to start looking at the following this weekend: time to first contact.
* MW: This week I summarized the krase 2015 article. I also worked on the referral dataset from last week, making the reporter relation variable into more general categories.

### Group 2

* BA: 1. Read two articles alloted to me and wrote a brief summary and how that fits into our analysis. A few questions popped up while doing so which migh be helpful in our analysis. 2. Cleaned the redundant code in the R file and upated it on github. Created a pull request to include the changes in the original file. 3. Created 3 types of race variables and created vizualizations for almost all the decison points. Have few questions on how to formulate the problem for few decision points.
* AW: Read through the assigned articles and gained a better understanding of the different ways that researchers can measure disproportionality. I enjoyed reading the two reports from University of Illinois and Child Welfare of Minnesota. The methods used in UofI-Urbana Champaign was more applicable to our data set and more likely for us to implement, while the ones from the Minnesota report heavily relied on data that we do not have. For example, it needed family conditions and reporter type, and these are data that CVille's CPS do not have.
* CM: This week I split my script into three parts (cleaning, analysis, and visualization) and got the data better organized and ready for analysis. Next week I want to dig more into the statistical models and make sure I really understand them. 
* NP: This week I worked on the Hornstein article and summary, read the childmaltreatment article, and looked at the prep_basedisp code.
* BE: I read and summarized the report, "Racial Disproportionality in Wisconsin's Child Welfare System" and posted my summary on Box ("bowman_etal_2009_summary_RGE."). I also updated my group's google doc page, just with our current charge and where we are, conglomerating messages between us, the lab's online pages, and the email from you last week. I peered into codes/scripts posted on Box, still trying to gain an understanding of R commands and keeping my own giant script updated with my notes. I am currently trying to *fully* understand piping. 

## 2018-03-02
* MC: pulled together some articles -- from the research synthesis and a search in web of science of work since 2011 -- read abstracts, downloaded ones that seemed most relevant, skimmed to situate it within our work, and sent out summary info to lab; sent race coding instructions. Downoaded and wrangled ACS 5-year estimates to generate estimates of children by race in Cville, merged with summary data on referrals by race (see `prep_basedisp.R`) and started lookiing at data (see `analysis_basedisp.R`). Updated GitHub and webpages with agenda.

### Group 1

* NP: This week my group met and revised our work plan to include only questions relating to the referral and the on going data. We discussed some initial thoughts about exploring this data and how to code the new race variables. In the end, we split up different outcomes to graph visually with race to get a feel for the distribution of our data. We will present these in class. 
* HS: This week my group met and revised our work plan to include only questions relating to the referral and the on going data. We discussed some initial thoughts about exploring this data and how to code the new race variables. In the end, we split up different outcomes to graph visually with race to get a feel for the distribution of our data. We will present these in class. 
* MW: I met with my team members to discuss how we should reframe our proposal to focus on the referral data. We came up with a few new variables, and decided which ones to do exploratory analysis on. I was assigned to graph the differences between first reporter relation for each race, which I uploaded to our team google drive.
* MW: My group and I (Group 1) met and determined our new questions using only the Referral and Ongoing Clients data. We organized what charts we wanted to use to determine the relationship between race and the data points (we choose mostly bar charts for now) and split them up accordingly. I made the bar charts for (Acceptance Frequency vs. Race) and (Screened Out vs. Race) for each of the 3 definitions of race we defined last class to see any differences between the results. I also made a google powerpoint to help the group show their results while I am not there in person. 

### Group 2

* BA: Created three new variables for race based on the your email last week. Re-organizing the data since there are many dataframes in our R code last week. Tried to create more conscise and clear datasets. Explored the variables that can go into the models at decisions points discussed for the foster care data which has unique client ids. Copied the variables from the placement data to foster care dataframe,  the variables which were unique for clients such as number of placements and time in placements etc.
* AW:  I played around with the data sets to do preliminary analysis, I had a hard time manipulating the data into the difference codings of race. I watched a couple videos on lynda.com but still had a little trouble applying it to our data. I look forward to learning what other people has done with the preliminary analysis in class, I think I'll learn a lot by seeing the different ways to do it. I have also read a couple chapters of the Child Maltreatment 2016 report.
* CM: This week, I did some baseline exploratory data analysis. It looks like placement category seems evenly broken up by race, where discharge from the system does seem to have some variation by race. I wondered whether face to face count was different for children of different racial categories, but after controlling for number of placements, there don’t seem to be significant differences. 

## 2018-02-23
* MC: added each group's code to read in, check, format data to GitHub (added a few comments or headers here and there); started a document on ShareLaTeX for collaborative report; started analysis plan for problem statement q1 (see `Q1update_feb22_mpc.doc,` `get_acs.R`); planned Friday's agenda and prepped short regression review; also added `git_steps.md` from publicpresidency repo as guidance to lab members who want to fork the repo and contribute directly via pull requests (if this describes you and you want to walk through things, let me know).

### Group 1

* NP: I caught up with last week's class material and read the resource carefully. I also reviewed the dataset again and found several interesting features I had not thought about. For instance,  the "face to face count” and “face to face home count” seems valuable for our research of racial disparity. Also, in the group discussion, I found that this dataset actually consists of information for nearly 20 years, and this finding makes me question whether the policies changes heavily influence the foster care system. Also, the demographic features may change a lot, and there may be more minorities in Charlottesville than before. Thus, I am wondering whether we should focus on count or percentage. 
* MW: This week I met with my group, where we discussed the variables and outcomes we wanted to use in tackling the problem. We made our discussion into a written report, which was then submitted. One thing we had trouble with was figuring out how to visualize any models we made, since the default decision tree output is not easily readable to an outsider.
* HS: This week I met up with my group and we talked through and created research plan based on the question we were given. This was mostly successful, though we do have some questions about our ability to pull neighborhood income from census tract and probably need more information about welfare policies that have changed over time that might affect our results. 
* MW: This week, our group developed our outline for research question #2: Racial disparity in post-referral decision points. Individually, I learned how to run the Monte Carlo analysis for the sensitivity of independent variables on dependent variables on excel. The result will be in the form of a distribution with confidence intervals, as well as an indication of the topmost "sensitive" variables in terms of influencing the dependent variable. Once our group runs the regression on our post-referral decision points, I hope to see if this analysis will add value and increased specificity to our analysis on R. 

### Group 2

* AW:  I worked with my team to go through the foster care data and explored ideas on how to identify disproportionality. It was also interesting to think about what factors should be included in our model, and learn about different ways to explore the dataset. Furthermore, on Wednesday, I  attended the "Data Manipulation with dplyr" workshop by the Health Sciences Library. I learned about the different verbs in the package, and now I feel more comfortable doing initial exploration. 
* CM: I met with my group, went over and explained our script to our new group members, and played around a little bit more with visualizations. I also made a GitHub, forked the project, and uploaded my script! I learned about survival models, and I think they could be useful in modeling time spent in the system.
* BA: We thought about what decision points might be critical in showing disparity. We have few points written down. But, we would have to build models to see which ones stand out. The details are included in the report. Other than that I was working on including some random forest models. But, will have to see if they work well comparatively.
* BE: First, I moved the data back into an encrypted folder on my desktop, deleted VeraCrypt and all that more complicated stuff, and fixed R and my working directory so that I could run mine and other peoples' scripts... Second, I communicated with my previous group about the foster care data code... read (new code) and compared it to old code that we had looked over in class and that you had made comments on. I made sure the new code addressed all these comments and we agreed that it did... Third, I met with my new group. We walked through (the) code step by step and talked through it, to make sure each of us understood what was happening. We had done some of this in class, but it was great to do it in a small group because things were explained at a different speed and using different language. Before our meeting, I had set up a google doc for our group with some basic info like the problem statement and our charge for the week and everyone's contact info. Everyone seemed to like it and agreed that they would like the doc to be updated with next week's assignment as well. We went onto this document as we discussed the question we are charged with and our role in addressing it.

## 2018-02-16
* MC: quick review of each group's code, more exploration of data, combine/revise problem statement for discussion and further revision, set Friday's agenda, read some literature on geographic context cited in the research synthesis.
* MW: This week I edited my R script and responded to the comments. I'm not sure whether the comments were made by you or by other students, but they were very helpful for clarifying and potential errors I made. Things that I might have found clear after looking extensively at the data might not be obvious to an outsider, so in the future I need to provide answers to these questions in my analysis. I also looked at the referral data and did the code review/added comments.
* HS: This week my group updated the code book with the additional information from Jenny. We also reviewed our code and incorporated the comments we received. This included adding more comments, grouping by case id and checking for outliers. One difficult part of the week was figuring out how to look for outliers in the data. We did a couple of things, but aren't sure if that is what to look for. I also created a version of the referral code with comments. 
* CM: This week I got some more census and ACS data by block group, updated my script with a binary indicator of ongoing cases, a duration variable with a dummy data retrieval date (not sure when that was), and explored some new visualization! N
* NP: Since last week in class our group realized that data visualization will be very important,  I am exploring new ways right now. Also, I am doing research about children’s psychology. I want to know whether we should keep exploring the age and gender effects. 
* AW: I was able to go through the explore_referraldata and my group's ongoing_clients data searched up functions that I didn't understand and didn't have a full grasp of. I now have more background on how the data is structured and better understand what should be done.
* MW: This week I looked more into potential tests we can do to analyze the data. There is this spreadsheet-based application called Oracle Crystal Ball that can be used to find the "sensitivity" of various variables and the impact of their potential values on the ultimate output variable. This could be used if later one we want to run a regression analysis on how various factors impact the likelihood of a child with being screened in. There are also other analyses on the probability and sensitivity of various variables on an outcome, called the Monte Carlo and Tornado Analysis. I will be attending a session on using Crystal Ball this afternoon so I will have a better idea of how to use it afterward. 

## 2018-02-09
* MC: updated explore_referraldata.R -- added comments, more cleaning, more exploration; set Friday's agenda, added code review questions


### Group 1 

* AW: My group and I explored the data for the Ongoing Clients, we were able to clean the data for it to be in a clearer format. I was also able to walk through our exploration R file from class and try to understand the steps. 
* HS: We explored the data set On_Going reports and renamed variables to make them clearer. We also factored categorical data points. We set up a meeting with Jenny Jones at DSS to explore our questions further.


### Group 2

* MW: I worked on the R Script for the Foster Care dataset. Since we don't have any questions to investigate yet, I just looked for differences between white and non-white kids in the system.
* NP: I used R to analyze the foster care dataset. I focused on the age variable. Here are some interesting findings:
  * First, generally, children whose age is around five have the highest chance to be put in the Legal Custody.
  * Second, girls and boys who are in the Legal Custody have different age distributions. For children whose age is below 8, boys are more likely to get into the Legal Custody. However, after 8, there are more girls getting into the Legal Custody.
  * Third, children from different races have different age distribution. For instance, African American children are more likely getting into the Legal Custody around age 1,5 and 15. However, white children are more likely to get into the Legal Custody at 16 and 17 years old.
* NP: This week I worked on looking through the Charlottesville open data. I identified 4 data sets that may be useful to us. The census tracts have geographical and demographic information that is relevant to our project. The crime data may be used to assess the risk that a child may face in a geographical area. Finally, the real estate assessment may give us some indication of income. 
* BE: NP uploaded the local, geographical data we thought would be useful from the Charlottesville Open Data Portal. The sets might relate to some of our lab's questions, to the census, or to foster children's exposure to social services or probability of harm. The open data chosen includes US Census Block Group Data, US Census Block Area, Crime Data, and Real Estate Current Assessments. Additionally, I had signed up for the "Help! I need to use the Census" workshop this week but had to miss that. 

### Group 3

* MW: I met with my group and we looked through the initial Social Explorer Tract Level ACS Census data. Specifically, I pulled out data on Charlottesville's 2016 Total Population, Sex, Sex by Age, Race, Poverty Status in for Children
 Under 18, Poverty Status based on Race, Means of Transportation to Work for Workers 16 Years and Over, and Travel Time to Work for Workers 16 years and Over.
* CM: I really enjoyed learning R and exploring the data this week. I’m new to R but I was able to build out a cleaning script, and that was the one my group decided to use so I was proud of that! I hit a number of roadblocks in trying to figure out how to group the placement data in a way it could be merged with the other data because placements are listed separated, but with extensive Googling and reading, I figured it out. 
* BA: We've cleaned up the placements data and created some new variables that we thought might be helpful. But, there are few questions in the that we wanted to run by you in orded to make changes to the data set. Secondly, going to the census workshop was of great help. But, after listening to Jenn talk about how the data is collected, I wouldn't recommend we use ACS data afterall. We would have to look if the 95% confidence intervals of the data aren't overlapping for all the tracts if we want to use them. Or we can't just prove that the data for the tracts are accurate or if there is a significant difference in the the tract data.
